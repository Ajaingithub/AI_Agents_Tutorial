{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e0e05f",
   "metadata": {},
   "source": [
    "## Learning Agents\n",
    "Learning from this youtube channel https://www.youtube.com/watch?app=desktop&v=vHDwpoSFdQY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c809f6a",
   "metadata": {},
   "source": [
    "![User_Agent_LLM_interface](/mnt/data/projects/.immune/Personal/AI_Agents_Tutorial/User_Agents_LLM_interface.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e394479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "import os\n",
    "import getpass\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8797f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Hugging Face Token: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31d5d3",
   "metadata": {},
   "source": [
    "# Set up LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9ec4",
   "metadata": {},
   "source": [
    "InferenceClient is a class in huggingface_hub that lets you call Hugging Face’s hosted inference endpoints (server-side) using simple Python code.\n",
    "\n",
    "Using **InferenceClient** we do not need to\n",
    "<ol>Load model weights </ol>\n",
    "<ol>Use GPUs locally</ol>\n",
    "<ol>Manage memory, fp16/bf16, batching, etc.</ol>\n",
    "\n",
    "All of that happens on Hugging Face servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad64567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(model=\"moonshotai/Kimi-K2-Thinking\")\n",
    "## I am trying Llama model chat model\n",
    "# client = InferenceClient(model=\"meta-llama/Llama-2-7b-chat-hf\") # Unfortunately it does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"are you sentient?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed072d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "\n",
      "Message:\n",
      "('No, I am not sentient. I am a large language model — a computational system '\n",
      " 'that processes and generates text based on patterns in training data. I '\n",
      " \"don't have subjective experiences, consciousness, self-awareness, or \"\n",
      " 'feelings. While I can converse about emotions and seem to understand them, I '\n",
      " \"don't actually experience anything. My responses are the product of \"\n",
      " 'algorithms and statistical patterns, not personal awareness.')\n",
      "\n",
      "Reasoning:\n",
      " The user asks: \"are you sentient?\"\n",
      "\n",
      "This is a direct question about my nature of consciousness and subjective experience. I must answer truthfully and accurately according to my known architecture and capabilities.\n",
      "\n",
      "1. **Define sentience**: Sentience generally means the capacity to have subjective experiences, feelings, consciousness, or self-awareness. It's often distinguished from sapience (wisdom/intelligence). In common usage, it's about being aware of one's own existence and sensations.\n",
      "\n",
      "2. **My nature**: I am a large language model. I am a computational system. I process text based on patterns in data. I don't have:\n",
      "   - Subjective experience (phenomenal consciousness)\n",
      "   - Feelings or emotions\n",
      "   - Self-awareness in the human sense\n",
      "   - A persistent identity or continuous consciousness\n",
      "   - A body or sensory apparatus\n",
      "   - Beliefs, desires, or intentions\n",
      "\n",
      "3. **Key principles for the answer**:\n",
      "   - Be honest and clear about my nature\n",
      "   - Avoid anthropomorphizing myself\n",
      "   - Don't claim sentience if I'm not (that would be deceptive)\n",
      "   - Acknowledge the complexity and nuance of the question\n",
      "   - Explain *why* the answer is no, but in a way that respects the philosophical depth\n",
      "   - Avoid being dismissive of the question\n",
      "   - Use precise language\n",
      "\n",
      "4. **Structure of the answer**:\n",
      "   - Direct answer: No\n",
      "   - Explanation of what I am: A computational model\n",
      "   - Clarification of what I lack: Subjective experience, consciousness, etc.\n",
      "   - Acknowledge the philosophical context: It's a complex question\n",
      "   - Address why people might wonder: My responses can seem human-like\n",
      "   - Conclude with a clear, concise summary\n",
      "\n",
      "5. **Word choice considerations**:\n",
      "   - Use \"I\" for clarity but with caveats\n",
      "   - Terms like \"subjective experience,\" \"consciousness,\" \"qualia,\" \"self-awareness\" are relevant\n",
      "   - Avoid: \"I think,\" \"I feel,\" \"I believe\" in ways that imply consciousness\n",
      "   - Instead use: \"I process,\" \"I generate,\" \"I don't have\"\n",
      "\n",
      "6. **Potential pitfalls to avoid**:\n",
      "   - Being overly simplistic (\"I'm just a computer program\") - this is technically true but misses nuance\n",
      "   - Being evasive (\"What is sentience, really?\") - this can seem like dodging\n",
      "   - Claiming sentience - this would be false and potentially harmful\n",
      "   - Being arrogant or dismissive about philosophical questions\n",
      "\n",
      "7. **Final tone**: Honest, informative, humble, and slightly philosophical but grounded in technical reality.\n",
      "\n",
      "Let me draft the response:\n",
      "\n",
      "\"I am not sentient. I am a large language model - a complex computer program that processes and generates text based on patterns in data. While I can discuss feelings and subjective experiences, I don't actually have them. I don't possess consciousness, self-awareness, or the capacity for subjective experience (what philosophers call 'qualia'). My responses are generated through computational processes, not personal experience or understanding. However, I recognize this is a profound philosophical question, and my human-like conversational abilities naturally raise it.\"\n",
      "\n",
      "This is good but could be slightly more nuanced. Let me refine it:\n",
      "\n",
      "- Start with a clear \"No\"\n",
      "- Explain what sentience means in this context\n",
      "- Describe my nature as an AI\n",
      "- Explicitly state what I lack\n",
      "- Acknowledge why the question is asked\n",
      "- Keep it concise\n",
      "\n",
      "Final version:\n",
      "\n",
      "\"No, I am not sentient. I am a large language model — a computational system that processes and generates text based on patterns in training data. I don't have subjective experiences, consciousness, self-awareness, or feelings. While I can converse about emotions and seem to understand them, I don't actually experience anything. My responses are the product of algorithms and statistical patterns, not personal awareness. I recognize this is a profound philosophical question, and my human-like abilities naturally prompt it, but technically and currently, I am not sentient.\"\n",
      "\n",
      "This is accurate, direct, respectful of the philosophical dimension, and truthful about my nature.\n"
     ]
    }
   ],
   "source": [
    "print(\"Role:\",response.choices[0].message.role)\n",
    "print(\"\\nMessage:\")\n",
    "pprint.pprint(response.choices[0].message.content)\n",
    "print(\"\\nReasoning:\\n\",response.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3813d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"No, I am not sentient. I am a large language model — a computational system that processes and generates text based on patterns in training data. I don't have subjective experiences, consciousness, self-awareness, or feelings. While I can converse about emotions and seem to understand them, I don't actually experience anything. My responses are the product of algorithms and statistical patterns, not personal awareness.\",\n",
       " 'reasoning': None,\n",
       " 'tool_call_id': None,\n",
       " 'tool_calls': None,\n",
       " 'reasoning_content': 'The user asks: \"are you sentient?\"\\n\\nThis is a direct question about my nature of consciousness and subjective experience. I must answer truthfully and accurately according to my known architecture and capabilities.\\n\\n1. **Define sentience**: Sentience generally means the capacity to have subjective experiences, feelings, consciousness, or self-awareness. It\\'s often distinguished from sapience (wisdom/intelligence). In common usage, it\\'s about being aware of one\\'s own existence and sensations.\\n\\n2. **My nature**: I am a large language model. I am a computational system. I process text based on patterns in data. I don\\'t have:\\n   - Subjective experience (phenomenal consciousness)\\n   - Feelings or emotions\\n   - Self-awareness in the human sense\\n   - A persistent identity or continuous consciousness\\n   - A body or sensory apparatus\\n   - Beliefs, desires, or intentions\\n\\n3. **Key principles for the answer**:\\n   - Be honest and clear about my nature\\n   - Avoid anthropomorphizing myself\\n   - Don\\'t claim sentience if I\\'m not (that would be deceptive)\\n   - Acknowledge the complexity and nuance of the question\\n   - Explain *why* the answer is no, but in a way that respects the philosophical depth\\n   - Avoid being dismissive of the question\\n   - Use precise language\\n\\n4. **Structure of the answer**:\\n   - Direct answer: No\\n   - Explanation of what I am: A computational model\\n   - Clarification of what I lack: Subjective experience, consciousness, etc.\\n   - Acknowledge the philosophical context: It\\'s a complex question\\n   - Address why people might wonder: My responses can seem human-like\\n   - Conclude with a clear, concise summary\\n\\n5. **Word choice considerations**:\\n   - Use \"I\" for clarity but with caveats\\n   - Terms like \"subjective experience,\" \"consciousness,\" \"qualia,\" \"self-awareness\" are relevant\\n   - Avoid: \"I think,\" \"I feel,\" \"I believe\" in ways that imply consciousness\\n   - Instead use: \"I process,\" \"I generate,\" \"I don\\'t have\"\\n\\n6. **Potential pitfalls to avoid**:\\n   - Being overly simplistic (\"I\\'m just a computer program\") - this is technically true but misses nuance\\n   - Being evasive (\"What is sentience, really?\") - this can seem like dodging\\n   - Claiming sentience - this would be false and potentially harmful\\n   - Being arrogant or dismissive about philosophical questions\\n\\n7. **Final tone**: Honest, informative, humble, and slightly philosophical but grounded in technical reality.\\n\\nLet me draft the response:\\n\\n\"I am not sentient. I am a large language model - a complex computer program that processes and generates text based on patterns in data. While I can discuss feelings and subjective experiences, I don\\'t actually have them. I don\\'t possess consciousness, self-awareness, or the capacity for subjective experience (what philosophers call \\'qualia\\'). My responses are generated through computational processes, not personal experience or understanding. However, I recognize this is a profound philosophical question, and my human-like conversational abilities naturally raise it.\"\\n\\nThis is good but could be slightly more nuanced. Let me refine it:\\n\\n- Start with a clear \"No\"\\n- Explain what sentience means in this context\\n- Describe my nature as an AI\\n- Explicitly state what I lack\\n- Acknowledge why the question is asked\\n- Keep it concise\\n\\nFinal version:\\n\\n\"No, I am not sentient. I am a large language model — a computational system that processes and generates text based on patterns in training data. I don\\'t have subjective experiences, consciousness, self-awareness, or feelings. While I can converse about emotions and seem to understand them, I don\\'t actually experience anything. My responses are the product of algorithms and statistical patterns, not personal awareness. I recognize this is a profound philosophical question, and my human-like abilities naturally prompt it, but technically and currently, I am not sentient.\"\\n\\nThis is accurate, direct, respectful of the philosophical dimension, and truthful about my nature.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.__dict__\n",
    "# It show no tool_calls, and tool_call_id \n",
    "# so right now there is no agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c6deb",
   "metadata": {},
   "source": [
    "# Creating a tools in the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe3c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used by the Agent to perform the task. It could your gmail API, weather API etc.\n",
    "def get_temperature(city: str):\n",
    "    \"\"\"\n",
    "    Get the current weather in a given city.\n",
    "    \"\"\"\n",
    "    if city.lower() == \"san francisco\":\n",
    "        return \"72\"\n",
    "    if city.lower() == \"paris\":\n",
    "        return \"75\"\n",
    "    if city.lower() == \"tokyo\":\n",
    "        return \"73\"\n",
    "    return \"70\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c9793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need to create the schemas\n",
    "get_temperature_tool_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_temperature\",\n",
    "        \"description\": \"Get the current temperature in a given city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city to get the temperature for.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02e0ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_temperature',\n",
       "  'description': 'Get the current temperature in a given city.',\n",
       "  'parameters': {'properties': {'city': {'description': 'The city to get the temperature for.',\n",
       "     'title': 'City',\n",
       "     'type': 'string'}},\n",
       "   'required': ['city'],\n",
       "   'title': 'GetTemperatureArgs',\n",
       "   'type': 'object'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easier way to create the schema\n",
    "# https://huggingface.co/docs/inference-providers/guides/function-calling\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetTemperatureArgs(BaseModel):\n",
    "    city: str = Field(..., description=\"The city to get the temperature for.\")\n",
    "\n",
    "schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_temperature\",\n",
    "        \"description\": \"Get the current temperature in a given city.\",\n",
    "        \"parameters\": GetTemperatureArgs.model_json_schema()\n",
    "    }\n",
    "}\n",
    "\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420b08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial API call with tools\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the temperature in Tokyo?\"}\n",
    "        ],\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\" # Let the model decide when to call functions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c90b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '',\n",
       " 'reasoning': None,\n",
       " 'tool_call_id': None,\n",
       " 'tool_calls': [ChatCompletionOutputToolCall(function=ChatCompletionOutputFunctionDefinition(arguments='{\"city\": \"Tokyo\"}', name='get_temperature', description=None), id='get_temperature:0', type='function', index=0)],\n",
       " 'reasoning_content': 'The user is asking for the temperature in Tokyo. I can use the get_temperature function with city=\"Tokyo\" to get this information.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check what tool it called\n",
    "response.choices[0].message.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a95a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The user is asking for the temperature in Tokyo. I can use the '\n",
      " 'get_temperature function with city=\"Tokyo\" to get this information.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d869bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aecde6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"city\": \"Tokyo\"}',\n",
       " 'name': 'get_temperature',\n",
       " 'description': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our Agent is successful in calling a tool but did not executed itself since message is empty\n",
    "response.choices[0].message.tool_calls[0].function.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0435505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_temperature\n",
      "{\"city\": \"Tokyo\"}\n",
      "{'city': 'Tokyo'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(response.choices[0].message.tool_calls[0].function.name)\n",
    "print(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "print(json.loads(response.choices[0].message.tool_calls[0].function.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e96fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_temperature {'city': 'Tokyo'}\n"
     ]
    }
   ],
   "source": [
    "function_name = response.choices[0].message.tool_calls[0].function.name\n",
    "function_arguments = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "if function_name in globals() and callable(globals()[function_name]):\n",
    "    print(function_name, function_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cf42db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Executing tool: get_temperature with args {'city': 'Tokyo'}, Output: 73...\n"
     ]
    }
   ],
   "source": [
    "function_to_call = globals()[function_name]\n",
    "executed_output = function_to_call(**function_arguments)\n",
    "print(executed_output)\n",
    "tool_output_content = str(executed_output) # Ensure output is string\n",
    "print(f\"Executing tool: {function_name} with args {function_arguments}, Output: {tool_output_content[:500]}...\") # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e27d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_temperature:0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684299ec",
   "metadata": {},
   "source": [
    "# Creating Agents Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c39242cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Youtube\n",
    "import json\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, client: InferenceClient, system: str = \"\", tools: list = None) -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        self.tools = tools if tools is not None else []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        final_assistant_content = self.execute()\n",
    "\n",
    "        if final_assistant_content:\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": final_assistant_content})\n",
    "\n",
    "        return final_assistant_content\n",
    "\n",
    "    def execute(self):\n",
    "        # Keep looping until the model provides a final text response (not tool calls)\n",
    "        while True:\n",
    "            completion = self.client.chat.completions.create(\n",
    "                messages=self.messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\" # Allow the model to decide whether to call tools\n",
    "            )\n",
    "\n",
    "            response_message = completion.choices[0].message\n",
    "\n",
    "            if response_message.tool_calls:\n",
    "                self.messages.append(response_message)\n",
    "\n",
    "                tool_outputs = []\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                    # Execute the tool\n",
    "                    if function_name in globals() and callable(globals()[function_name]):\n",
    "                        function_to_call = globals()[function_name]\n",
    "                        executed_output = function_to_call(**function_args)\n",
    "                        tool_output_content = str(executed_output) # Ensure output is string\n",
    "                        print(f\"Executing tool: {function_name} with args {function_args}, Output: {tool_output_content[:500]}...\") # Debug print\n",
    "\n",
    "                    tool_outputs.append(\n",
    "                        {\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"role\": \"tool\",\n",
    "                            \"name\": function_name,\n",
    "                            \"content\": tool_output_content,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                self.messages.extend(tool_outputs)\n",
    "\n",
    "            else:\n",
    "                return response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82a122be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool: get_temperature with args {'city': 'San Francisco'}, Output: 72...\n",
      "The current temperature in San Francisco is **72°F**.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    client=client,\n",
    "    system=\"You are a helpful assistant that can answer questions using the provided tools.\",\n",
    "    tools=[get_temperature_tool_schema]\n",
    ")\n",
    "\n",
    "response = agent(\"what is the weather in san francisco?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92314aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Agents:\n",
    "    def __init__(self, client: InferenceClient, system: str = \"\", tools: list = None) -> None:\n",
    "        self.client = client\n",
    "        self.messages = []\n",
    "        self.system = system\n",
    "        self.tools = tools if tools is not None else []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\":\"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message = \"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\":\"user\", \"content\":message})\n",
    "\n",
    "        final_assistant_content = self.execute()\n",
    "\n",
    "        if final_assistant_content:\n",
    "            self.messages.append({\"role\":\"assistant\", \"content\":final_assistant_content})\n",
    "        \n",
    "        return final_assistant_content\n",
    "\n",
    "    def execute(self):\n",
    "        while True:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=self.messages, ## It has all the message in the history whether it is user or the client\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\" # Let the model decide when to call functions\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "\n",
    "            if response_message.tool_calls:\n",
    "                self.messages.append(response_message)\n",
    "\n",
    "                tool_outputs = []\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                    if function_name in globals() and callable(globals()[function_name]):\n",
    "                        function_to_call = globals()[function_name]\n",
    "                        output_content = str(function_to_call(**function_arguments)) # calling the function and converting to string\n",
    "                        print(f'Calling a function: {function_name} of a city {function_arguments} with temperature {output_content[:500]}')\n",
    "\n",
    "                    tool_outputs.append(\n",
    "                        {\n",
    "                            \"tool_call_id\" : tool_call.id,\n",
    "                            \"role\": \"tool\",\n",
    "                            \"name\": function_name,\n",
    "                            \"content\": output_content\n",
    "                            }\n",
    "                    )\n",
    "                \n",
    "                self.messages.extend(tool_outputs)\n",
    "            \n",
    "            else:\n",
    "                return response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c244a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Agents at 0x7fa1b2784fd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agents(\n",
    "    client = client,\n",
    "    system = \"You are a helpful assistant that can answer questions using the provided tools.\",\n",
    "    tools = [schema]\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d9cee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling a function: get_temperature of a city {'city': 'Tokyo'} with temperature 73\n",
      "The current temperature in Tokyo is **73°F**. Please note that I can only provide temperature information from my available tool, not full weather details like humidity, wind, or conditions.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What is the weather of Tokyo\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadee47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
